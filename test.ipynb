{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "# Initialize a new run\n",
    "run = wandb.init(project=\"huggingface\", name=\"my_run\")\n",
    "\n",
    "# Your custom data\n",
    "my_custom_data = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "\n",
    "# Log the custom data\n",
    "wandb.log({\"eval/loss\": wandb.Table(data=my_custom_data, columns=[\"x\", \"y\", \"z\"])})\n",
    "\n",
    "# Finish the run\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "# Initialize the API\n",
    "api = wandb.Api()\n",
    "\n",
    "# Load the old run\n",
    "run = api.run(\"henry-hoang/huggingface/o3unf6do\")\n",
    "\n",
    "# # Change the data\n",
    "# run.config[\"foo\"] = 32\n",
    "\n",
    "# # Update the run\n",
    "# run.update()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eval/runtime</th>\n",
       "      <th>train/train_loss</th>\n",
       "      <th>train/train_samples_per_second</th>\n",
       "      <th>eval/loss</th>\n",
       "      <th>_timestamp</th>\n",
       "      <th>train/train_runtime</th>\n",
       "      <th>eval/samples_per_second</th>\n",
       "      <th>train/train_steps_per_second</th>\n",
       "      <th>train/loss</th>\n",
       "      <th>train/total_flos</th>\n",
       "      <th>_step</th>\n",
       "      <th>_runtime</th>\n",
       "      <th>train/epoch</th>\n",
       "      <th>train/global_step</th>\n",
       "      <th>train/learning_rate</th>\n",
       "      <th>eval/steps_per_second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.698851e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0742</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>69.514992</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>9.852217e-08</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.698852e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.1284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>253.796557</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "      <td>3.940887e-07</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.698852e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>501.275680</td>\n",
       "      <td>0.02</td>\n",
       "      <td>8</td>\n",
       "      <td>7.881773e-07</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.698852e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.1168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>736.185644</td>\n",
       "      <td>0.03</td>\n",
       "      <td>12</td>\n",
       "      <td>1.182266e-06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.698852e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.1224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>900.045730</td>\n",
       "      <td>0.04</td>\n",
       "      <td>16</td>\n",
       "      <td>1.576355e-06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.698976e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.7430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>508</td>\n",
       "      <td>124508.434593</td>\n",
       "      <td>3.48</td>\n",
       "      <td>2016</td>\n",
       "      <td>2.897529e-09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.698976e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.7226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>509</td>\n",
       "      <td>124681.516412</td>\n",
       "      <td>3.49</td>\n",
       "      <td>2020</td>\n",
       "      <td>1.478366e-09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.698976e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.7166</td>\n",
       "      <td>NaN</td>\n",
       "      <td>510</td>\n",
       "      <td>124939.871342</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2024</td>\n",
       "      <td>5.322201e-10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.698977e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.7129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>511</td>\n",
       "      <td>125198.358560</td>\n",
       "      <td>3.51</td>\n",
       "      <td>2028</td>\n",
       "      <td>5.913604e-11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.778528</td>\n",
       "      <td>8.293</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.698977e+09</td>\n",
       "      <td>125331.2953</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.191489e+16</td>\n",
       "      <td>512</td>\n",
       "      <td>125328.478740</td>\n",
       "      <td>3.51</td>\n",
       "      <td>2030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     eval/runtime  train/train_loss  train/train_samples_per_second  \\\n",
       "0             NaN               NaN                             NaN   \n",
       "1             NaN               NaN                             NaN   \n",
       "2             NaN               NaN                             NaN   \n",
       "3             NaN               NaN                             NaN   \n",
       "4             NaN               NaN                             NaN   \n",
       "..            ...               ...                             ...   \n",
       "495           NaN               NaN                             NaN   \n",
       "496           NaN               NaN                             NaN   \n",
       "497           NaN               NaN                             NaN   \n",
       "498           NaN               NaN                             NaN   \n",
       "499           NaN          1.778528                           8.293   \n",
       "\n",
       "     eval/loss    _timestamp  train/train_runtime  eval/samples_per_second  \\\n",
       "0          NaN  1.698851e+09                  NaN                      NaN   \n",
       "1          NaN  1.698852e+09                  NaN                      NaN   \n",
       "2          NaN  1.698852e+09                  NaN                      NaN   \n",
       "3          NaN  1.698852e+09                  NaN                      NaN   \n",
       "4          NaN  1.698852e+09                  NaN                      NaN   \n",
       "..         ...           ...                  ...                      ...   \n",
       "495        NaN  1.698976e+09                  NaN                      NaN   \n",
       "496        NaN  1.698976e+09                  NaN                      NaN   \n",
       "497        NaN  1.698976e+09                  NaN                      NaN   \n",
       "498        NaN  1.698977e+09                  NaN                      NaN   \n",
       "499        NaN  1.698977e+09          125331.2953                      NaN   \n",
       "\n",
       "     train/train_steps_per_second  train/loss  train/total_flos  _step  \\\n",
       "0                             NaN      2.0742               NaN      0   \n",
       "1                             NaN      2.1284               NaN      1   \n",
       "2                             NaN      2.0902               NaN      2   \n",
       "3                             NaN      2.1168               NaN      3   \n",
       "4                             NaN      2.1224               NaN      4   \n",
       "..                            ...         ...               ...    ...   \n",
       "495                           NaN      1.7430               NaN    508   \n",
       "496                           NaN      1.7226               NaN    509   \n",
       "497                           NaN      1.7166               NaN    510   \n",
       "498                           NaN      1.7129               NaN    511   \n",
       "499                         0.016         NaN      4.191489e+16    512   \n",
       "\n",
       "          _runtime  train/epoch  train/global_step  train/learning_rate  \\\n",
       "0        69.514992         0.00                  1         9.852217e-08   \n",
       "1       253.796557         0.01                  4         3.940887e-07   \n",
       "2       501.275680         0.02                  8         7.881773e-07   \n",
       "3       736.185644         0.03                 12         1.182266e-06   \n",
       "4       900.045730         0.04                 16         1.576355e-06   \n",
       "..             ...          ...                ...                  ...   \n",
       "495  124508.434593         3.48               2016         2.897529e-09   \n",
       "496  124681.516412         3.49               2020         1.478366e-09   \n",
       "497  124939.871342         3.50               2024         5.322201e-10   \n",
       "498  125198.358560         3.51               2028         5.913604e-11   \n",
       "499  125328.478740         3.51               2030                  NaN   \n",
       "\n",
       "     eval/steps_per_second  \n",
       "0                      NaN  \n",
       "1                      NaN  \n",
       "2                      NaN  \n",
       "3                      NaN  \n",
       "4                      NaN  \n",
       "..                     ...  \n",
       "495                    NaN  \n",
       "496                    NaN  \n",
       "497                    NaN  \n",
       "498                    NaN  \n",
       "499                    NaN  \n",
       "\n",
       "[500 rows x 16 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['bf16', 'fp16', 'fsdp', 'seed', 'tf32', 'debug', 'n_ctx', 'optim', 'top_k', 'top_p', 'n_embd', 'n_head', 'prefix', 'do_eval', 'n_inner', 'n_layer', 'no_cuda', 'use_cpu', 'do_train', 'id2label', 'label2id', 'run_name', 'use_ipex', 'adafactor', 'data_seed', 'deepspeed', 'do_sample', 'hub_token', 'log_level', 'max_steps', 'n_special', 'num_beams', 'ray_scope', 'report_to', 'typical_p', 'use_cache', 'adam_beta1', 'adam_beta2', 'attn_pdrop', 'do_predict', 'embd_pdrop', 'eval_delay', 'eval_steps', 'is_decoder', 'local_rank', 'max_length', 'min_length', 'model_type', 'optim_args', 'output_dir', 'past_index', 'save_steps', 'vocab_size', 'ddp_backend', 'ddp_timeout', 'fsdp_config', 'label_names', 'logging_dir', 'n_positions', 'push_to_hub', 'resid_pdrop', 'return_dict', 'sharded_ddp', 'temperature', 'torch_dtype', 'torchdynamo', 'torchscript', 'adam_epsilon', 'bos_token_id', 'disable_tqdm', 'eos_token_id', 'fp16_backend', 'hub_model_id', 'hub_strategy', 'pad_token_id', 'problem_type', 'pruned_heads', 'sep_token_id', 'summary_type', 'use_bfloat16', 'warmup_ratio', 'warmup_steps', 'weight_decay', '_name_or_path', 'architectures', 'bad_words_ids', 'jit_mode_eval', 'learning_rate', 'logging_steps', 'max_grad_norm', 'mp_parameters', 'output_scores', 'save_strategy', 'torch_compile', 'tpu_num_cores', 'bf16_full_eval', 'early_stopping', 'fp16_full_eval', 'fp16_opt_level', 'length_penalty', 'tf_legacy_loss', 'use_mps_device', 'finetuning_task', 'group_by_length', 'hub_always_push', 'num_beam_groups', 'suppress_tokens', 'tokenizer_class', 'dispatch_batches', 'full_determinism', 'hub_private_repo', 'ignore_data_skip', 'log_on_each_node', 'logging_strategy', 'num_train_epochs', 'save_safetensors', 'save_total_limit', 'summary_use_proj', 'ddp_bucket_cap_mb', 'diversity_penalty', 'greater_is_better', 'initializer_range', 'log_level_replica', 'lr_scheduler_type', 'output_attentions', 'push_to_hub_token', 'save_on_each_node', 'tpu_metrics_debug', 'is_encoder_decoder', 'layer_norm_epsilon', 'length_column_name', 'logging_first_step', 'repetition_penalty', 'scale_attn_weights', 'summary_activation', 'torch_compile_mode', 'activation_function', 'add_cross_attention', 'evaluation_strategy', 'forced_bos_token_id', 'forced_eos_token_id', 'fsdp_min_num_params', 'skip_memory_metrics', 'tie_encoder_decoder', 'tie_word_embeddings', 'auto_find_batch_size', 'dataloader_drop_last', 'no_repeat_ngram_size', 'num_return_sequences', 'output_hidden_states', 'overwrite_output_dir', 'prediction_loss_only', 'push_to_hub_model_id', 'task_specific_params', 'transformers_version', 'begin_suppress_tokens', 'dataloader_pin_memory', 'ddp_broadcast_buffers', 'metric_for_best_model', 'remove_invalid_values', 'remove_unused_columns', 'summary_first_dropout', 'torch_compile_backend', 'dataloader_num_workers', 'decoder_start_token_id', 'gradient_checkpointing', 'half_precision_backend', 'label_smoothing_factor', 'load_best_model_at_end', 'logging_nan_inf_filter', 'predict_special_tokens', 'resume_from_checkpoint', 'summary_proj_to_labels', 'chunk_size_feed_forward', 'eval_accumulation_steps', 'per_gpu_eval_batch_size', 'reorder_and_upcast_attn', 'return_dict_in_generate', 'per_gpu_train_batch_size', 'push_to_hub_organization', 'include_tokens_per_second', 'ddp_find_unused_parameters', 'include_inputs_for_metrics', 'per_device_eval_batch_size', 'use_legacy_prediction_loop', 'cross_attention_hidden_size', 'gradient_accumulation_steps', 'per_device_train_batch_size', 'encoder_no_repeat_ngram_size', 'scale_attn_by_inverse_layer_idx', 'exponential_decay_length_penalty', 'fsdp_transformer_layer_cls_to_wrap'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.config.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cz4042",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
